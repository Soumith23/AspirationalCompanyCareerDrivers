{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073e47e4",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "- Sai Bhargav Tetali\n",
    "- Soumith Reddy Palreddy\n",
    "- Srividya Rayaprolu\n",
    "- Shubhada Kapre\n",
    "- Akhila Guttikonda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee085900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, nltk, lda\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import PunktSentenceTokenizer, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import PunktSentenceTokenizer,RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e2c2c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netflix\n",
      "Bank of America\n",
      "EY\n",
      "Target\n",
      "PWC\n",
      "Spotify\n",
      "Apple\n",
      "Deloitte\n",
      "KPMG\n",
      "Google\n",
      "J P Morgan Chase\n",
      "Amazon\n",
      "Meta\n",
      "P&G\n",
      "Goldman Sachs\n",
      "Walmart\n",
      "BCG\n",
      "Mc Kinsey\n",
      "Loreal\n",
      "Bain and Company\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# importing all the excel files and combining the data\n",
    "import os\n",
    "import glob\n",
    "  \n",
    "# use glob to get all the xlsx files in the folder\n",
    "path = os.getcwd()\n",
    "csv_files = glob.glob(os.path.join(path, \"*.xlsx\"))\n",
    "\n",
    "df = pd.DataFrame(columns = ['Company','Pros', 'Cons'])\n",
    "\n",
    "for f in csv_files:\n",
    "    #read the csv file\n",
    "    if f.count('_') == 1:\n",
    "        df_temp = pd.read_excel(f,  nrows=500)\n",
    "        df_temp = df_temp[['Pros','Cons']]\n",
    "        df_temp['Company'] = f.split(\"/\")[-1].split(\"_\")[0]\n",
    "        df = pd.concat([df,df_temp])\n",
    "        print(f.split(\"/\")[-1].split(\"_\")[0])\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26edee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#droppping null rows if any\n",
    "df = df.dropna()\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "company_name = 'Company'\n",
    "company_review_pros = 'Pros'\n",
    "company_review_cons = 'Cons'\n",
    "#determining the number of topics. This number has been decided after running the code multiple times and checking\n",
    "# the ouput\n",
    "ntopics= 3\n",
    "\n",
    "# data preprocessing - lemmatization, stopwords removal\n",
    "word_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stopwords_nltk=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2691ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(version_desc):\n",
    "    # converting the all the text to lowercase\n",
    "    lowercase=version_desc.lower()\n",
    "    text = wordnet_lemmatizer.lemmatize(lowercase)\n",
    "    tokens = word_tokenizer.tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63dd1703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saibhargavtetali/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 6593)\n",
      "(9999, 9605)\n"
     ]
    }
   ],
   "source": [
    "# Countvectorizer for the pros column\n",
    "vec_words_pros = CountVectorizer(tokenizer=tokenize_text,stop_words=stopwords_nltk,decode_error='ignore')\n",
    "# Countvectorizer for the cons column\n",
    "vec_words_cons = CountVectorizer(tokenizer=tokenize_text,stop_words=stopwords_nltk,decode_error='ignore')\n",
    "\n",
    "total_features_words_pros = vec_words_pros.fit_transform(df[company_review_pros])\n",
    "total_features_words_cons = vec_words_cons.fit_transform(df[company_review_cons])\n",
    "\n",
    "print(total_features_words_pros.shape)\n",
    "print(total_features_words_cons.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbf81429",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 9999\n",
      "INFO:lda:vocab_size: 6593\n",
      "INFO:lda:n_words: 98845\n",
      "INFO:lda:n_topics: 3\n",
      "INFO:lda:n_iter: 500\n",
      "INFO:lda:<0> log likelihood: -849471\n",
      "INFO:lda:<10> log likelihood: -738180\n",
      "INFO:lda:<20> log likelihood: -728621\n",
      "INFO:lda:<30> log likelihood: -719874\n",
      "INFO:lda:<40> log likelihood: -712358\n",
      "INFO:lda:<50> log likelihood: -707223\n",
      "INFO:lda:<60> log likelihood: -703956\n",
      "INFO:lda:<70> log likelihood: -702323\n",
      "INFO:lda:<80> log likelihood: -701558\n",
      "INFO:lda:<90> log likelihood: -700493\n",
      "INFO:lda:<100> log likelihood: -700481\n",
      "INFO:lda:<110> log likelihood: -699924\n",
      "INFO:lda:<120> log likelihood: -699589\n",
      "INFO:lda:<130> log likelihood: -699078\n",
      "INFO:lda:<140> log likelihood: -699522\n",
      "INFO:lda:<150> log likelihood: -699590\n",
      "INFO:lda:<160> log likelihood: -699135\n",
      "INFO:lda:<170> log likelihood: -699048\n",
      "INFO:lda:<180> log likelihood: -699041\n",
      "INFO:lda:<190> log likelihood: -699315\n",
      "INFO:lda:<200> log likelihood: -699368\n",
      "INFO:lda:<210> log likelihood: -699117\n",
      "INFO:lda:<220> log likelihood: -698716\n",
      "INFO:lda:<230> log likelihood: -698974\n",
      "INFO:lda:<240> log likelihood: -698902\n",
      "INFO:lda:<250> log likelihood: -699116\n",
      "INFO:lda:<260> log likelihood: -698663\n",
      "INFO:lda:<270> log likelihood: -698598\n",
      "INFO:lda:<280> log likelihood: -698896\n",
      "INFO:lda:<290> log likelihood: -698768\n",
      "INFO:lda:<300> log likelihood: -698261\n",
      "INFO:lda:<310> log likelihood: -698458\n",
      "INFO:lda:<320> log likelihood: -698776\n",
      "INFO:lda:<330> log likelihood: -698592\n",
      "INFO:lda:<340> log likelihood: -698686\n",
      "INFO:lda:<350> log likelihood: -698650\n",
      "INFO:lda:<360> log likelihood: -698678\n",
      "INFO:lda:<370> log likelihood: -698811\n",
      "INFO:lda:<380> log likelihood: -698808\n",
      "INFO:lda:<390> log likelihood: -698586\n",
      "INFO:lda:<400> log likelihood: -698591\n",
      "INFO:lda:<410> log likelihood: -698402\n",
      "INFO:lda:<420> log likelihood: -698593\n",
      "INFO:lda:<430> log likelihood: -698472\n",
      "INFO:lda:<440> log likelihood: -698552\n",
      "INFO:lda:<450> log likelihood: -698174\n",
      "INFO:lda:<460> log likelihood: -698245\n",
      "INFO:lda:<470> log likelihood: -698477\n",
      "INFO:lda:<480> log likelihood: -698534\n",
      "INFO:lda:<490> log likelihood: -698460\n",
      "INFO:lda:<499> log likelihood: -698185\n",
      "INFO:lda:n_documents: 9999\n",
      "INFO:lda:vocab_size: 9605\n",
      "INFO:lda:n_words: 116934\n",
      "INFO:lda:n_topics: 3\n",
      "INFO:lda:n_iter: 500\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -1094488\n",
      "INFO:lda:<10> log likelihood: -971615\n",
      "INFO:lda:<20> log likelihood: -958768\n",
      "INFO:lda:<30> log likelihood: -950862\n",
      "INFO:lda:<40> log likelihood: -942488\n",
      "INFO:lda:<50> log likelihood: -936383\n",
      "INFO:lda:<60> log likelihood: -932238\n",
      "INFO:lda:<70> log likelihood: -929615\n",
      "INFO:lda:<80> log likelihood: -927258\n",
      "INFO:lda:<90> log likelihood: -926381\n",
      "INFO:lda:<100> log likelihood: -925323\n",
      "INFO:lda:<110> log likelihood: -924888\n",
      "INFO:lda:<120> log likelihood: -923615\n",
      "INFO:lda:<130> log likelihood: -923070\n",
      "INFO:lda:<140> log likelihood: -922734\n",
      "INFO:lda:<150> log likelihood: -922347\n",
      "INFO:lda:<160> log likelihood: -922675\n",
      "INFO:lda:<170> log likelihood: -921802\n",
      "INFO:lda:<180> log likelihood: -922166\n",
      "INFO:lda:<190> log likelihood: -922201\n",
      "INFO:lda:<200> log likelihood: -921723\n",
      "INFO:lda:<210> log likelihood: -921695\n",
      "INFO:lda:<220> log likelihood: -921619\n",
      "INFO:lda:<230> log likelihood: -921424\n",
      "INFO:lda:<240> log likelihood: -921456\n",
      "INFO:lda:<250> log likelihood: -921487\n",
      "INFO:lda:<260> log likelihood: -921358\n",
      "INFO:lda:<270> log likelihood: -921229\n",
      "INFO:lda:<280> log likelihood: -921132\n",
      "INFO:lda:<290> log likelihood: -921240\n",
      "INFO:lda:<300> log likelihood: -921476\n",
      "INFO:lda:<310> log likelihood: -921448\n",
      "INFO:lda:<320> log likelihood: -921641\n",
      "INFO:lda:<330> log likelihood: -921133\n",
      "INFO:lda:<340> log likelihood: -921191\n",
      "INFO:lda:<350> log likelihood: -921286\n",
      "INFO:lda:<360> log likelihood: -921516\n",
      "INFO:lda:<370> log likelihood: -921319\n",
      "INFO:lda:<380> log likelihood: -921831\n",
      "INFO:lda:<390> log likelihood: -922131\n",
      "INFO:lda:<400> log likelihood: -921733\n",
      "INFO:lda:<410> log likelihood: -921841\n",
      "INFO:lda:<420> log likelihood: -921375\n",
      "INFO:lda:<430> log likelihood: -921894\n",
      "INFO:lda:<440> log likelihood: -921525\n",
      "INFO:lda:<450> log likelihood: -921792\n",
      "INFO:lda:<460> log likelihood: -921747\n",
      "INFO:lda:<470> log likelihood: -921821\n",
      "INFO:lda:<480> log likelihood: -921776\n",
      "INFO:lda:<490> log likelihood: -921446\n",
      "INFO:lda:<499> log likelihood: -921913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Pros</th>\n",
       "      <th>Cons</th>\n",
       "      <th>0_pros</th>\n",
       "      <th>1_pros</th>\n",
       "      <th>2_pros</th>\n",
       "      <th>0_cons</th>\n",
       "      <th>1_cons</th>\n",
       "      <th>2_cons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>Very competitive pay, and competent teams to g...</td>\n",
       "      <td>A lot of turnover, constant corporate level ch...</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>- Paycheck\\n- So many good people\\n- Such a gr...</td>\n",
       "      <td>I have been working for a year at Netflix.\\n\\n...</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.211033</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.788707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>Big name\\nAll cash comp (for now)</td>\n",
       "      <td>Cost cutting environment\\nManagement lacks vis...</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.980583</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.009709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>Netflix has been a wild and wonderful ride. Th...</td>\n",
       "      <td>It is not for everyone. If you need stability,...</td>\n",
       "      <td>0.206107</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.791349</td>\n",
       "      <td>0.549488</td>\n",
       "      <td>0.139932</td>\n",
       "      <td>0.310580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>The pay when all engineers were senior enginee...</td>\n",
       "      <td>There is a great deal of politics between Engi...</td>\n",
       "      <td>0.071895</td>\n",
       "      <td>0.267974</td>\n",
       "      <td>0.660131</td>\n",
       "      <td>0.675520</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.323762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>Bain and Company</td>\n",
       "      <td>Huge focus on professional development.  Teams...</td>\n",
       "      <td>Hours can obviously be long but this is often ...</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.252033</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Bain and Company</td>\n",
       "      <td>Really smart people, fulfilling work, will alw...</td>\n",
       "      <td>Not a lot, sometimes the work can get overwhel...</td>\n",
       "      <td>0.373494</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.614458</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Bain and Company</td>\n",
       "      <td>High impact work, smart and humble coworkers.</td>\n",
       "      <td>Long hours. Work can be stressful at times whe...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Bain and Company</td>\n",
       "      <td>Great company culture, great mentorship and le...</td>\n",
       "      <td>Highly variable experience based on your proje...</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.174603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Bain and Company</td>\n",
       "      <td>Best place to work.... hands down. Amazing tea...</td>\n",
       "      <td>Long hours, high stress, lots of travel.\\n\\nDo...</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.316062</td>\n",
       "      <td>0.419689</td>\n",
       "      <td>0.264249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9999 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company                                               Pros  \\\n",
       "0              Netflix  Very competitive pay, and competent teams to g...   \n",
       "1              Netflix  - Paycheck\\n- So many good people\\n- Such a gr...   \n",
       "2              Netflix                  Big name\\nAll cash comp (for now)   \n",
       "3              Netflix  Netflix has been a wild and wonderful ride. Th...   \n",
       "4              Netflix  The pay when all engineers were senior enginee...   \n",
       "...                ...                                                ...   \n",
       "9994  Bain and Company  Huge focus on professional development.  Teams...   \n",
       "9995  Bain and Company  Really smart people, fulfilling work, will alw...   \n",
       "9996  Bain and Company      High impact work, smart and humble coworkers.   \n",
       "9997  Bain and Company  Great company culture, great mentorship and le...   \n",
       "9998  Bain and Company  Best place to work.... hands down. Amazing tea...   \n",
       "\n",
       "                                                   Cons    0_pros    1_pros  \\\n",
       "0     A lot of turnover, constant corporate level ch...  0.962264  0.018868   \n",
       "1     I have been working for a year at Netflix.\\n\\n...  0.561644  0.287671   \n",
       "2     Cost cutting environment\\nManagement lacks vis...  0.953488  0.023256   \n",
       "3     It is not for everyone. If you need stability,...  0.206107  0.002545   \n",
       "4     There is a great deal of politics between Engi...  0.071895  0.267974   \n",
       "...                                                 ...       ...       ...   \n",
       "9994  Hours can obviously be long but this is often ...  0.689320  0.009709   \n",
       "9995  Not a lot, sometimes the work can get overwhel...  0.373494  0.012048   \n",
       "9996  Long hours. Work can be stressful at times whe...  0.809524  0.174603   \n",
       "9997  Highly variable experience based on your proje...  0.972603  0.013699   \n",
       "9998  Long hours, high stress, lots of travel.\\n\\nDo...  0.320158  0.043478   \n",
       "\n",
       "        2_pros    0_cons    1_cons    2_cons  \n",
       "0     0.018868  0.968254  0.015873  0.015873  \n",
       "1     0.150685  0.211033  0.000260  0.788707  \n",
       "2     0.023256  0.980583  0.009709  0.009709  \n",
       "3     0.791349  0.549488  0.139932  0.310580  \n",
       "4     0.660131  0.675520  0.000718  0.323762  \n",
       "...        ...       ...       ...       ...  \n",
       "9994  0.300971  0.252033  0.414634  0.333333  \n",
       "9995  0.614458  0.015873  0.968254  0.015873  \n",
       "9996  0.015873  0.015873  0.968254  0.015873  \n",
       "9997  0.013699  0.015873  0.809524  0.174603  \n",
       "9998  0.636364  0.316062  0.419689  0.264249  \n",
       "\n",
       "[9999 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning LDA function to a variable\n",
    "model = lda.LDA(n_topics=int(ntopics), n_iter=500, random_state=1)\n",
    "# fitting the model on words in pros column \n",
    "model.fit(total_features_words_pros)\n",
    "\n",
    "topic_word_pros = model.topic_word_\n",
    "doc_topic_pros = model.doc_topic_\n",
    "doc_topic_pros = pd.DataFrame(doc_topic_pros)\n",
    "df = df.join(doc_topic_pros)\n",
    "\n",
    "# assigning LDA function to a variable\n",
    "model = lda.LDA(n_topics=int(ntopics), n_iter=500, random_state=1)\n",
    "# fitting the model on words in cons column\n",
    "model.fit(total_features_words_cons)\n",
    "\n",
    "topic_word_cons = model.topic_word_\n",
    "doc_topic_cons = model.doc_topic_\n",
    "doc_topic_cons = pd.DataFrame(doc_topic_cons)\n",
    "df = df.join(doc_topic_cons, lsuffix = '_pros', rsuffix = '_cons')\n",
    "# the result will give the proportion of each of the topics in each pros and cons reviews\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3459ad62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saibhargavtetali/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics word distribution written in file pros_topic_word_dist.xlsx \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saibhargavtetali/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics word distribution written in file cons_topic_word_dist.xlsx \n",
      "Document topic distribution written in file document_pros_topic_dist.xlsx \n"
     ]
    }
   ],
   "source": [
    "# creating a dataframe to store company wise topics distribution\n",
    "company = pd.DataFrame()\n",
    "for i in range(int(ntopics)):\n",
    "    topic=\"pros_topic_\" + str(i)\n",
    "    column = str(i)+'_pros'\n",
    "    company[topic]=df.groupby([company_name])[column].mean()\n",
    "for i in range(int(ntopics)):    \n",
    "    topic=\"cons_topic_\" + str(i)\n",
    "    column = str(i)+'_cons'\n",
    "    company[topic]=df.groupby([company_name])[column].mean()\n",
    "\n",
    "company = company.reset_index()\n",
    "\n",
    "# exporting the words in pros column with the probability distributions in each of the topics\n",
    "topics = pd.DataFrame(topic_word_pros)\n",
    "topics.columns=vec_words_pros.get_feature_names()\n",
    "topics1 = topics.transpose()\n",
    "print (\"Topics word distribution written in file pros_topic_word_dist.xlsx \")\n",
    "topics1.to_excel(\"pros_topic_word_dist.xlsx\")\n",
    "\n",
    "# exporting the words in cons column with the probability distributions in each of the topics\n",
    "topics = pd.DataFrame(topic_word_cons)\n",
    "topics.columns=vec_words_cons.get_feature_names()\n",
    "topics1 = topics.transpose()\n",
    "print (\"Topics word distribution written in file cons_topic_word_dist.xlsx \")\n",
    "topics1.to_excel(\"cons_topic_word_dist.xlsx\")\n",
    "\n",
    "\n",
    "# exporting the company wise topics distribution. The export format can be viewed below.\n",
    "company.to_excel(\"document_pros_topic_dist.xlsx\",index=False)\n",
    "print (\"Document topic distribution written in file document_pros_topic_dist.xlsx \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086e70fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>pros_topic_0</th>\n",
       "      <th>pros_topic_1</th>\n",
       "      <th>pros_topic_2</th>\n",
       "      <th>cons_topic_0</th>\n",
       "      <th>cons_topic_1</th>\n",
       "      <th>cons_topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>0.246579</td>\n",
       "      <td>0.319006</td>\n",
       "      <td>0.434415</td>\n",
       "      <td>0.337707</td>\n",
       "      <td>0.245711</td>\n",
       "      <td>0.416582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple</td>\n",
       "      <td>0.268632</td>\n",
       "      <td>0.477389</td>\n",
       "      <td>0.253980</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.340494</td>\n",
       "      <td>0.369603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCG</td>\n",
       "      <td>0.578254</td>\n",
       "      <td>0.208276</td>\n",
       "      <td>0.213470</td>\n",
       "      <td>0.253003</td>\n",
       "      <td>0.544966</td>\n",
       "      <td>0.202031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bain and Company</td>\n",
       "      <td>0.614222</td>\n",
       "      <td>0.085792</td>\n",
       "      <td>0.299986</td>\n",
       "      <td>0.237366</td>\n",
       "      <td>0.545280</td>\n",
       "      <td>0.217354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bank of America</td>\n",
       "      <td>0.301210</td>\n",
       "      <td>0.463573</td>\n",
       "      <td>0.235216</td>\n",
       "      <td>0.398997</td>\n",
       "      <td>0.251279</td>\n",
       "      <td>0.349723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>0.490967</td>\n",
       "      <td>0.284709</td>\n",
       "      <td>0.224324</td>\n",
       "      <td>0.391564</td>\n",
       "      <td>0.396323</td>\n",
       "      <td>0.212113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EY</td>\n",
       "      <td>0.498335</td>\n",
       "      <td>0.263119</td>\n",
       "      <td>0.238546</td>\n",
       "      <td>0.315437</td>\n",
       "      <td>0.472396</td>\n",
       "      <td>0.212167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>0.484829</td>\n",
       "      <td>0.279999</td>\n",
       "      <td>0.235172</td>\n",
       "      <td>0.354234</td>\n",
       "      <td>0.414158</td>\n",
       "      <td>0.231608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Google</td>\n",
       "      <td>0.358361</td>\n",
       "      <td>0.389952</td>\n",
       "      <td>0.251687</td>\n",
       "      <td>0.404467</td>\n",
       "      <td>0.217689</td>\n",
       "      <td>0.377845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>J P Morgan Chase</td>\n",
       "      <td>0.333619</td>\n",
       "      <td>0.391246</td>\n",
       "      <td>0.275135</td>\n",
       "      <td>0.479311</td>\n",
       "      <td>0.226352</td>\n",
       "      <td>0.294337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KPMG</td>\n",
       "      <td>0.480127</td>\n",
       "      <td>0.263798</td>\n",
       "      <td>0.256075</td>\n",
       "      <td>0.298634</td>\n",
       "      <td>0.490008</td>\n",
       "      <td>0.211358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Loreal</td>\n",
       "      <td>0.375518</td>\n",
       "      <td>0.291225</td>\n",
       "      <td>0.333257</td>\n",
       "      <td>0.437737</td>\n",
       "      <td>0.236689</td>\n",
       "      <td>0.325575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mc Kinsey</td>\n",
       "      <td>0.600793</td>\n",
       "      <td>0.158878</td>\n",
       "      <td>0.240329</td>\n",
       "      <td>0.270589</td>\n",
       "      <td>0.529551</td>\n",
       "      <td>0.199860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Meta</td>\n",
       "      <td>0.415842</td>\n",
       "      <td>0.295195</td>\n",
       "      <td>0.288963</td>\n",
       "      <td>0.457186</td>\n",
       "      <td>0.207168</td>\n",
       "      <td>0.335645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>0.261209</td>\n",
       "      <td>0.316624</td>\n",
       "      <td>0.422167</td>\n",
       "      <td>0.339884</td>\n",
       "      <td>0.180839</td>\n",
       "      <td>0.479277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P&amp;G</td>\n",
       "      <td>0.394334</td>\n",
       "      <td>0.341704</td>\n",
       "      <td>0.263962</td>\n",
       "      <td>0.439906</td>\n",
       "      <td>0.266905</td>\n",
       "      <td>0.293189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PWC</td>\n",
       "      <td>0.466332</td>\n",
       "      <td>0.273573</td>\n",
       "      <td>0.260095</td>\n",
       "      <td>0.267292</td>\n",
       "      <td>0.516452</td>\n",
       "      <td>0.216256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Spotify</td>\n",
       "      <td>0.380939</td>\n",
       "      <td>0.314530</td>\n",
       "      <td>0.304531</td>\n",
       "      <td>0.549825</td>\n",
       "      <td>0.142438</td>\n",
       "      <td>0.307738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Target</td>\n",
       "      <td>0.186613</td>\n",
       "      <td>0.599633</td>\n",
       "      <td>0.213754</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.412536</td>\n",
       "      <td>0.357764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>0.137033</td>\n",
       "      <td>0.610600</td>\n",
       "      <td>0.252368</td>\n",
       "      <td>0.203795</td>\n",
       "      <td>0.319311</td>\n",
       "      <td>0.476894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company  pros_topic_0  pros_topic_1  pros_topic_2  cons_topic_0  \\\n",
       "0             Amazon      0.246579      0.319006      0.434415      0.337707   \n",
       "1              Apple      0.268632      0.477389      0.253980      0.289903   \n",
       "2                BCG      0.578254      0.208276      0.213470      0.253003   \n",
       "3   Bain and Company      0.614222      0.085792      0.299986      0.237366   \n",
       "4    Bank of America      0.301210      0.463573      0.235216      0.398997   \n",
       "5           Deloitte      0.490967      0.284709      0.224324      0.391564   \n",
       "6                 EY      0.498335      0.263119      0.238546      0.315437   \n",
       "7      Goldman Sachs      0.484829      0.279999      0.235172      0.354234   \n",
       "8             Google      0.358361      0.389952      0.251687      0.404467   \n",
       "9   J P Morgan Chase      0.333619      0.391246      0.275135      0.479311   \n",
       "10              KPMG      0.480127      0.263798      0.256075      0.298634   \n",
       "11            Loreal      0.375518      0.291225      0.333257      0.437737   \n",
       "12         Mc Kinsey      0.600793      0.158878      0.240329      0.270589   \n",
       "13              Meta      0.415842      0.295195      0.288963      0.457186   \n",
       "14           Netflix      0.261209      0.316624      0.422167      0.339884   \n",
       "15               P&G      0.394334      0.341704      0.263962      0.439906   \n",
       "16               PWC      0.466332      0.273573      0.260095      0.267292   \n",
       "17           Spotify      0.380939      0.314530      0.304531      0.549825   \n",
       "18            Target      0.186613      0.599633      0.213754      0.229700   \n",
       "19           Walmart      0.137033      0.610600      0.252368      0.203795   \n",
       "\n",
       "    cons_topic_1  cons_topic_2  \n",
       "0       0.245711      0.416582  \n",
       "1       0.340494      0.369603  \n",
       "2       0.544966      0.202031  \n",
       "3       0.545280      0.217354  \n",
       "4       0.251279      0.349723  \n",
       "5       0.396323      0.212113  \n",
       "6       0.472396      0.212167  \n",
       "7       0.414158      0.231608  \n",
       "8       0.217689      0.377845  \n",
       "9       0.226352      0.294337  \n",
       "10      0.490008      0.211358  \n",
       "11      0.236689      0.325575  \n",
       "12      0.529551      0.199860  \n",
       "13      0.207168      0.335645  \n",
       "14      0.180839      0.479277  \n",
       "15      0.266905      0.293189  \n",
       "16      0.516452      0.216256  \n",
       "17      0.142438      0.307738  \n",
       "18      0.412536      0.357764  \n",
       "19      0.319311      0.476894  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company # company topics distribution. Here topics are not yet known to us. We will detrmine the tpics by looking \n",
    "# at the word probability distributions we exported in the above for pros and cons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41af75f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amazon</th>\n",
       "      <th>Apple</th>\n",
       "      <th>BCG</th>\n",
       "      <th>Bain and Company</th>\n",
       "      <th>Bank of America</th>\n",
       "      <th>Deloitte</th>\n",
       "      <th>EY</th>\n",
       "      <th>Goldman Sachs</th>\n",
       "      <th>Google</th>\n",
       "      <th>J P Morgan Chase</th>\n",
       "      <th>KPMG</th>\n",
       "      <th>Loreal</th>\n",
       "      <th>Mc Kinsey</th>\n",
       "      <th>Meta</th>\n",
       "      <th>Netflix</th>\n",
       "      <th>P&amp;G</th>\n",
       "      <th>PWC</th>\n",
       "      <th>Spotify</th>\n",
       "      <th>Target</th>\n",
       "      <th>Walmart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267590</td>\n",
       "      <td>0.560219</td>\n",
       "      <td>0.589171</td>\n",
       "      <td>0.267996</td>\n",
       "      <td>0.415249</td>\n",
       "      <td>0.445574</td>\n",
       "      <td>0.401055</td>\n",
       "      <td>0.240126</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.439001</td>\n",
       "      <td>0.214475</td>\n",
       "      <td>0.566406</td>\n",
       "      <td>0.269601</td>\n",
       "      <td>0.092269</td>\n",
       "      <td>0.278424</td>\n",
       "      <td>0.446242</td>\n",
       "      <td>0.320076</td>\n",
       "      <td>0.417127</td>\n",
       "      <td>0.396429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.267590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.491100</td>\n",
       "      <td>0.585470</td>\n",
       "      <td>0.147853</td>\n",
       "      <td>0.354531</td>\n",
       "      <td>0.376496</td>\n",
       "      <td>0.338623</td>\n",
       "      <td>0.209704</td>\n",
       "      <td>0.258187</td>\n",
       "      <td>0.371252</td>\n",
       "      <td>0.294848</td>\n",
       "      <td>0.526208</td>\n",
       "      <td>0.320940</td>\n",
       "      <td>0.306926</td>\n",
       "      <td>0.260895</td>\n",
       "      <td>0.368309</td>\n",
       "      <td>0.390262</td>\n",
       "      <td>0.179565</td>\n",
       "      <td>0.233325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.560219</td>\n",
       "      <td>0.491100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155758</td>\n",
       "      <td>0.521327</td>\n",
       "      <td>0.234466</td>\n",
       "      <td>0.138891</td>\n",
       "      <td>0.206340</td>\n",
       "      <td>0.493742</td>\n",
       "      <td>0.508308</td>\n",
       "      <td>0.140414</td>\n",
       "      <td>0.454703</td>\n",
       "      <td>0.064971</td>\n",
       "      <td>0.461825</td>\n",
       "      <td>0.610584</td>\n",
       "      <td>0.418018</td>\n",
       "      <td>0.142069</td>\n",
       "      <td>0.565527</td>\n",
       "      <td>0.590657</td>\n",
       "      <td>0.697814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.589171</td>\n",
       "      <td>0.585470</td>\n",
       "      <td>0.155758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612350</td>\n",
       "      <td>0.326309</td>\n",
       "      <td>0.245120</td>\n",
       "      <td>0.299523</td>\n",
       "      <td>0.566839</td>\n",
       "      <td>0.582097</td>\n",
       "      <td>0.241744</td>\n",
       "      <td>0.497371</td>\n",
       "      <td>0.103624</td>\n",
       "      <td>0.509862</td>\n",
       "      <td>0.636209</td>\n",
       "      <td>0.489291</td>\n",
       "      <td>0.245871</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.701223</td>\n",
       "      <td>0.790538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.267996</td>\n",
       "      <td>0.147853</td>\n",
       "      <td>0.521327</td>\n",
       "      <td>0.612350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328858</td>\n",
       "      <td>0.392234</td>\n",
       "      <td>0.331512</td>\n",
       "      <td>0.104435</td>\n",
       "      <td>0.134217</td>\n",
       "      <td>0.398203</td>\n",
       "      <td>0.217104</td>\n",
       "      <td>0.546807</td>\n",
       "      <td>0.223407</td>\n",
       "      <td>0.288765</td>\n",
       "      <td>0.171651</td>\n",
       "      <td>0.411656</td>\n",
       "      <td>0.264071</td>\n",
       "      <td>0.294679</td>\n",
       "      <td>0.328283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.415249</td>\n",
       "      <td>0.354531</td>\n",
       "      <td>0.234466</td>\n",
       "      <td>0.326309</td>\n",
       "      <td>0.328858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110928</td>\n",
       "      <td>0.047636</td>\n",
       "      <td>0.298249</td>\n",
       "      <td>0.286427</td>\n",
       "      <td>0.137755</td>\n",
       "      <td>0.256370</td>\n",
       "      <td>0.246346</td>\n",
       "      <td>0.255495</td>\n",
       "      <td>0.461985</td>\n",
       "      <td>0.199542</td>\n",
       "      <td>0.178611</td>\n",
       "      <td>0.343623</td>\n",
       "      <td>0.489486</td>\n",
       "      <td>0.586137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.445574</td>\n",
       "      <td>0.376496</td>\n",
       "      <td>0.138891</td>\n",
       "      <td>0.245120</td>\n",
       "      <td>0.392234</td>\n",
       "      <td>0.110928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075852</td>\n",
       "      <td>0.368921</td>\n",
       "      <td>0.372868</td>\n",
       "      <td>0.035107</td>\n",
       "      <td>0.328969</td>\n",
       "      <td>0.163697</td>\n",
       "      <td>0.340678</td>\n",
       "      <td>0.499759</td>\n",
       "      <td>0.286219</td>\n",
       "      <td>0.076638</td>\n",
       "      <td>0.440139</td>\n",
       "      <td>0.493112</td>\n",
       "      <td>0.597873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.401055</td>\n",
       "      <td>0.338623</td>\n",
       "      <td>0.206340</td>\n",
       "      <td>0.299523</td>\n",
       "      <td>0.331512</td>\n",
       "      <td>0.047636</td>\n",
       "      <td>0.075852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301439</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.099881</td>\n",
       "      <td>0.262666</td>\n",
       "      <td>0.222406</td>\n",
       "      <td>0.268610</td>\n",
       "      <td>0.449776</td>\n",
       "      <td>0.213639</td>\n",
       "      <td>0.138792</td>\n",
       "      <td>0.366987</td>\n",
       "      <td>0.472212</td>\n",
       "      <td>0.567757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.240126</td>\n",
       "      <td>0.209704</td>\n",
       "      <td>0.493742</td>\n",
       "      <td>0.566839</td>\n",
       "      <td>0.104435</td>\n",
       "      <td>0.298249</td>\n",
       "      <td>0.368921</td>\n",
       "      <td>0.301439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117533</td>\n",
       "      <td>0.379259</td>\n",
       "      <td>0.144551</td>\n",
       "      <td>0.509075</td>\n",
       "      <td>0.135437</td>\n",
       "      <td>0.244328</td>\n",
       "      <td>0.120902</td>\n",
       "      <td>0.399324</td>\n",
       "      <td>0.201736</td>\n",
       "      <td>0.379229</td>\n",
       "      <td>0.397592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.258187</td>\n",
       "      <td>0.508308</td>\n",
       "      <td>0.582097</td>\n",
       "      <td>0.134217</td>\n",
       "      <td>0.286427</td>\n",
       "      <td>0.372868</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.117533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383556</td>\n",
       "      <td>0.133974</td>\n",
       "      <td>0.520585</td>\n",
       "      <td>0.136901</td>\n",
       "      <td>0.296891</td>\n",
       "      <td>0.097284</td>\n",
       "      <td>0.408525</td>\n",
       "      <td>0.145541</td>\n",
       "      <td>0.412064</td>\n",
       "      <td>0.452943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.439001</td>\n",
       "      <td>0.371252</td>\n",
       "      <td>0.140414</td>\n",
       "      <td>0.241744</td>\n",
       "      <td>0.398203</td>\n",
       "      <td>0.137755</td>\n",
       "      <td>0.035107</td>\n",
       "      <td>0.099881</td>\n",
       "      <td>0.379259</td>\n",
       "      <td>0.383556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337961</td>\n",
       "      <td>0.168222</td>\n",
       "      <td>0.356068</td>\n",
       "      <td>0.497363</td>\n",
       "      <td>0.299869</td>\n",
       "      <td>0.044806</td>\n",
       "      <td>0.456017</td>\n",
       "      <td>0.482613</td>\n",
       "      <td>0.588761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.214475</td>\n",
       "      <td>0.294848</td>\n",
       "      <td>0.454703</td>\n",
       "      <td>0.497371</td>\n",
       "      <td>0.217104</td>\n",
       "      <td>0.256370</td>\n",
       "      <td>0.328969</td>\n",
       "      <td>0.262666</td>\n",
       "      <td>0.144551</td>\n",
       "      <td>0.133974</td>\n",
       "      <td>0.337961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454325</td>\n",
       "      <td>0.070391</td>\n",
       "      <td>0.240698</td>\n",
       "      <td>0.098338</td>\n",
       "      <td>0.364939</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.469382</td>\n",
       "      <td>0.499871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.566406</td>\n",
       "      <td>0.526208</td>\n",
       "      <td>0.064971</td>\n",
       "      <td>0.103624</td>\n",
       "      <td>0.546807</td>\n",
       "      <td>0.246346</td>\n",
       "      <td>0.163697</td>\n",
       "      <td>0.222406</td>\n",
       "      <td>0.509075</td>\n",
       "      <td>0.520585</td>\n",
       "      <td>0.168222</td>\n",
       "      <td>0.454325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460805</td>\n",
       "      <td>0.614607</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.179100</td>\n",
       "      <td>0.562274</td>\n",
       "      <td>0.637820</td>\n",
       "      <td>0.738025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.269601</td>\n",
       "      <td>0.320940</td>\n",
       "      <td>0.461825</td>\n",
       "      <td>0.509862</td>\n",
       "      <td>0.223407</td>\n",
       "      <td>0.255495</td>\n",
       "      <td>0.340678</td>\n",
       "      <td>0.268610</td>\n",
       "      <td>0.135437</td>\n",
       "      <td>0.136901</td>\n",
       "      <td>0.356068</td>\n",
       "      <td>0.070391</td>\n",
       "      <td>0.460805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277844</td>\n",
       "      <td>0.094448</td>\n",
       "      <td>0.387066</td>\n",
       "      <td>0.124037</td>\n",
       "      <td>0.495278</td>\n",
       "      <td>0.524680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.092269</td>\n",
       "      <td>0.306926</td>\n",
       "      <td>0.610584</td>\n",
       "      <td>0.636209</td>\n",
       "      <td>0.288765</td>\n",
       "      <td>0.461985</td>\n",
       "      <td>0.499759</td>\n",
       "      <td>0.449776</td>\n",
       "      <td>0.244328</td>\n",
       "      <td>0.296891</td>\n",
       "      <td>0.497363</td>\n",
       "      <td>0.240698</td>\n",
       "      <td>0.614607</td>\n",
       "      <td>0.277844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.308902</td>\n",
       "      <td>0.507230</td>\n",
       "      <td>0.321175</td>\n",
       "      <td>0.457913</td>\n",
       "      <td>0.410334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.278424</td>\n",
       "      <td>0.260895</td>\n",
       "      <td>0.418018</td>\n",
       "      <td>0.489291</td>\n",
       "      <td>0.171651</td>\n",
       "      <td>0.199542</td>\n",
       "      <td>0.286219</td>\n",
       "      <td>0.213639</td>\n",
       "      <td>0.120902</td>\n",
       "      <td>0.097284</td>\n",
       "      <td>0.299869</td>\n",
       "      <td>0.098338</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.094448</td>\n",
       "      <td>0.308902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328373</td>\n",
       "      <td>0.174211</td>\n",
       "      <td>0.426335</td>\n",
       "      <td>0.480505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.446242</td>\n",
       "      <td>0.368309</td>\n",
       "      <td>0.142069</td>\n",
       "      <td>0.245871</td>\n",
       "      <td>0.411656</td>\n",
       "      <td>0.178611</td>\n",
       "      <td>0.076638</td>\n",
       "      <td>0.138792</td>\n",
       "      <td>0.399324</td>\n",
       "      <td>0.408525</td>\n",
       "      <td>0.044806</td>\n",
       "      <td>0.364939</td>\n",
       "      <td>0.179100</td>\n",
       "      <td>0.387066</td>\n",
       "      <td>0.507230</td>\n",
       "      <td>0.328373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488901</td>\n",
       "      <td>0.467912</td>\n",
       "      <td>0.576987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.320076</td>\n",
       "      <td>0.390262</td>\n",
       "      <td>0.565527</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.264071</td>\n",
       "      <td>0.343623</td>\n",
       "      <td>0.440139</td>\n",
       "      <td>0.366987</td>\n",
       "      <td>0.201736</td>\n",
       "      <td>0.145541</td>\n",
       "      <td>0.456017</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.562274</td>\n",
       "      <td>0.124037</td>\n",
       "      <td>0.321175</td>\n",
       "      <td>0.174211</td>\n",
       "      <td>0.488901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552470</td>\n",
       "      <td>0.574023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.417127</td>\n",
       "      <td>0.179565</td>\n",
       "      <td>0.590657</td>\n",
       "      <td>0.701223</td>\n",
       "      <td>0.294679</td>\n",
       "      <td>0.489486</td>\n",
       "      <td>0.493112</td>\n",
       "      <td>0.472212</td>\n",
       "      <td>0.379229</td>\n",
       "      <td>0.412064</td>\n",
       "      <td>0.482613</td>\n",
       "      <td>0.469382</td>\n",
       "      <td>0.637820</td>\n",
       "      <td>0.495278</td>\n",
       "      <td>0.457913</td>\n",
       "      <td>0.426335</td>\n",
       "      <td>0.467912</td>\n",
       "      <td>0.552470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.396429</td>\n",
       "      <td>0.233325</td>\n",
       "      <td>0.697814</td>\n",
       "      <td>0.790538</td>\n",
       "      <td>0.328283</td>\n",
       "      <td>0.586137</td>\n",
       "      <td>0.597873</td>\n",
       "      <td>0.567757</td>\n",
       "      <td>0.397592</td>\n",
       "      <td>0.452943</td>\n",
       "      <td>0.588761</td>\n",
       "      <td>0.499871</td>\n",
       "      <td>0.738025</td>\n",
       "      <td>0.524680</td>\n",
       "      <td>0.410334</td>\n",
       "      <td>0.480505</td>\n",
       "      <td>0.576987</td>\n",
       "      <td>0.574023</td>\n",
       "      <td>0.166203</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Amazon     Apple       BCG  Bain and Company  Bank of America  Deloitte  \\\n",
       "0   0.000000  0.267590  0.560219          0.589171         0.267996  0.415249   \n",
       "1   0.267590  0.000000  0.491100          0.585470         0.147853  0.354531   \n",
       "2   0.560219  0.491100  0.000000          0.155758         0.521327  0.234466   \n",
       "3   0.589171  0.585470  0.155758          0.000000         0.612350  0.326309   \n",
       "4   0.267996  0.147853  0.521327          0.612350         0.000000  0.328858   \n",
       "5   0.415249  0.354531  0.234466          0.326309         0.328858  0.000000   \n",
       "6   0.445574  0.376496  0.138891          0.245120         0.392234  0.110928   \n",
       "7   0.401055  0.338623  0.206340          0.299523         0.331512  0.047636   \n",
       "8   0.240126  0.209704  0.493742          0.566839         0.104435  0.298249   \n",
       "9   0.271174  0.258187  0.508308          0.582097         0.134217  0.286427   \n",
       "10  0.439001  0.371252  0.140414          0.241744         0.398203  0.137755   \n",
       "11  0.214475  0.294848  0.454703          0.497371         0.217104  0.256370   \n",
       "12  0.566406  0.526208  0.064971          0.103624         0.546807  0.246346   \n",
       "13  0.269601  0.320940  0.461825          0.509862         0.223407  0.255495   \n",
       "14  0.092269  0.306926  0.610584          0.636209         0.288765  0.461985   \n",
       "15  0.278424  0.260895  0.418018          0.489291         0.171651  0.199542   \n",
       "16  0.446242  0.368309  0.142069          0.245871         0.411656  0.178611   \n",
       "17  0.320076  0.390262  0.565527          0.612245         0.264071  0.343623   \n",
       "18  0.417127  0.179565  0.590657          0.701223         0.294679  0.489486   \n",
       "19  0.396429  0.233325  0.697814          0.790538         0.328283  0.586137   \n",
       "\n",
       "          EY  Goldman Sachs    Google  J P Morgan Chase      KPMG    Loreal  \\\n",
       "0   0.445574       0.401055  0.240126          0.271174  0.439001  0.214475   \n",
       "1   0.376496       0.338623  0.209704          0.258187  0.371252  0.294848   \n",
       "2   0.138891       0.206340  0.493742          0.508308  0.140414  0.454703   \n",
       "3   0.245120       0.299523  0.566839          0.582097  0.241744  0.497371   \n",
       "4   0.392234       0.331512  0.104435          0.134217  0.398203  0.217104   \n",
       "5   0.110928       0.047636  0.298249          0.286427  0.137755  0.256370   \n",
       "6   0.000000       0.075852  0.368921          0.372868  0.035107  0.328969   \n",
       "7   0.075852       0.000000  0.301439          0.302800  0.099881  0.262666   \n",
       "8   0.368921       0.301439  0.000000          0.117533  0.379259  0.144551   \n",
       "9   0.372868       0.302800  0.117533          0.000000  0.383556  0.133974   \n",
       "10  0.035107       0.099881  0.379259          0.383556  0.000000  0.337961   \n",
       "11  0.328969       0.262666  0.144551          0.133974  0.337961  0.000000   \n",
       "12  0.163697       0.222406  0.509075          0.520585  0.168222  0.454325   \n",
       "13  0.340678       0.268610  0.135437          0.136901  0.356068  0.070391   \n",
       "14  0.499759       0.449776  0.244328          0.296891  0.497363  0.240698   \n",
       "15  0.286219       0.213639  0.120902          0.097284  0.299869  0.098338   \n",
       "16  0.076638       0.138792  0.399324          0.408525  0.044806  0.364939   \n",
       "17  0.440139       0.366987  0.201736          0.145541  0.456017  0.152193   \n",
       "18  0.493112       0.472212  0.379229          0.412064  0.482613  0.469382   \n",
       "19  0.597873       0.567757  0.397592          0.452943  0.588761  0.499871   \n",
       "\n",
       "    Mc Kinsey      Meta   Netflix       P&G       PWC   Spotify    Target  \\\n",
       "0    0.566406  0.269601  0.092269  0.278424  0.446242  0.320076  0.417127   \n",
       "1    0.526208  0.320940  0.306926  0.260895  0.368309  0.390262  0.179565   \n",
       "2    0.064971  0.461825  0.610584  0.418018  0.142069  0.565527  0.590657   \n",
       "3    0.103624  0.509862  0.636209  0.489291  0.245871  0.612245  0.701223   \n",
       "4    0.546807  0.223407  0.288765  0.171651  0.411656  0.264071  0.294679   \n",
       "5    0.246346  0.255495  0.461985  0.199542  0.178611  0.343623  0.489486   \n",
       "6    0.163697  0.340678  0.499759  0.286219  0.076638  0.440139  0.493112   \n",
       "7    0.222406  0.268610  0.449776  0.213639  0.138792  0.366987  0.472212   \n",
       "8    0.509075  0.135437  0.244328  0.120902  0.399324  0.201736  0.379229   \n",
       "9    0.520585  0.136901  0.296891  0.097284  0.408525  0.145541  0.412064   \n",
       "10   0.168222  0.356068  0.497363  0.299869  0.044806  0.456017  0.482613   \n",
       "11   0.454325  0.070391  0.240698  0.098338  0.364939  0.152193  0.469382   \n",
       "12   0.000000  0.460805  0.614607  0.427751  0.179100  0.562274  0.637820   \n",
       "13   0.460805  0.000000  0.277844  0.094448  0.387066  0.124037  0.495278   \n",
       "14   0.614607  0.277844  0.000000  0.308902  0.507230  0.321175  0.457913   \n",
       "15   0.427751  0.094448  0.308902  0.000000  0.328373  0.174211  0.426335   \n",
       "16   0.179100  0.387066  0.507230  0.328373  0.000000  0.488901  0.467912   \n",
       "17   0.562274  0.124037  0.321175  0.174211  0.488901  0.000000  0.552470   \n",
       "18   0.637820  0.495278  0.457913  0.426335  0.467912  0.552470  0.000000   \n",
       "19   0.738025  0.524680  0.410334  0.480505  0.576987  0.574023  0.166203   \n",
       "\n",
       "     Walmart  \n",
       "0   0.396429  \n",
       "1   0.233325  \n",
       "2   0.697814  \n",
       "3   0.790538  \n",
       "4   0.328283  \n",
       "5   0.586137  \n",
       "6   0.597873  \n",
       "7   0.567757  \n",
       "8   0.397592  \n",
       "9   0.452943  \n",
       "10  0.588761  \n",
       "11  0.499871  \n",
       "12  0.738025  \n",
       "13  0.524680  \n",
       "14  0.410334  \n",
       "15  0.480505  \n",
       "16  0.576987  \n",
       "17  0.574023  \n",
       "18  0.166203  \n",
       "19  0.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating Euclidean distances between companies by taking the topic proportions as vector elements. Each company\n",
    "# vector will have 6 elements - 3 pros and 3 cons\n",
    "def Euclidean_d(x,l):\n",
    "    d_list = []\n",
    "    for i in l:\n",
    "        d_list.append(np.sqrt((np.square(company_dict[i] - company_dict[x])).sum()))\n",
    "        \n",
    "    return d_list\n",
    "    \n",
    "        \n",
    "company_dict = {}\n",
    "company_list = company['Company'].to_list()\n",
    "company_vectors = company[['pros_topic_0','pros_topic_1','pros_topic_2','cons_topic_0','cons_topic_1','cons_topic_2']].to_numpy()\n",
    "for i in range(len(company_list)):\n",
    "    company_dict[company_list[i]] = company_vectors[i]\n",
    "\n",
    "distance_dict = {}\n",
    "for i in company_list:\n",
    "    distance_dict[i] = Euclidean_d(i,company_list)\n",
    "    \n",
    "mds_df = pd.DataFrame(distance_dict)\n",
    "mds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18e7557b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.26759034, 0.5602193 , 0.5891712 , 0.26799634,\n",
       "        0.41524872, 0.44557401, 0.40105504, 0.24012633, 0.27117382,\n",
       "        0.43900089, 0.2144752 , 0.56640603, 0.26960105, 0.092269  ,\n",
       "        0.27842439, 0.44624218, 0.32007625, 0.41712692, 0.39642875],\n",
       "       [0.26759034, 0.        , 0.49109968, 0.58546964, 0.14785278,\n",
       "        0.35453129, 0.37649609, 0.33862291, 0.20970435, 0.2581865 ,\n",
       "        0.37125165, 0.29484824, 0.52620803, 0.32093978, 0.30692631,\n",
       "        0.26089539, 0.36830882, 0.39026206, 0.17956463, 0.23332514],\n",
       "       [0.5602193 , 0.49109968, 0.        , 0.15575806, 0.5213268 ,\n",
       "        0.23446588, 0.13889053, 0.20634016, 0.49374179, 0.50830782,\n",
       "        0.14041419, 0.45470346, 0.06497089, 0.46182486, 0.61058438,\n",
       "        0.41801845, 0.1420688 , 0.56552701, 0.59065731, 0.69781391],\n",
       "       [0.5891712 , 0.58546964, 0.15575806, 0.        , 0.61235049,\n",
       "        0.32630875, 0.2451197 , 0.29952251, 0.56683902, 0.58209684,\n",
       "        0.2417443 , 0.49737097, 0.10362399, 0.50986155, 0.63620858,\n",
       "        0.4892911 , 0.24587061, 0.61224524, 0.70122269, 0.7905383 ],\n",
       "       [0.26799634, 0.14785278, 0.5213268 , 0.61235049, 0.        ,\n",
       "        0.32885845, 0.39223428, 0.33151193, 0.10443513, 0.13421735,\n",
       "        0.39820329, 0.21710435, 0.54680744, 0.22340672, 0.28876458,\n",
       "        0.17165136, 0.41165598, 0.26407052, 0.29467878, 0.32828298],\n",
       "       [0.41524872, 0.35453129, 0.23446588, 0.32630875, 0.32885845,\n",
       "        0.        , 0.11092844, 0.04763625, 0.29824876, 0.28642698,\n",
       "        0.1377552 , 0.25637015, 0.24634637, 0.25549521, 0.46198452,\n",
       "        0.19954164, 0.17861133, 0.34362296, 0.48948616, 0.58613718],\n",
       "       [0.44557401, 0.37649609, 0.13889053, 0.2451197 , 0.39223428,\n",
       "        0.11092844, 0.        , 0.07585177, 0.36892103, 0.37286827,\n",
       "        0.03510679, 0.32896871, 0.16369669, 0.34067758, 0.49975907,\n",
       "        0.28621949, 0.07663808, 0.44013943, 0.49311186, 0.59787299],\n",
       "       [0.40105504, 0.33862291, 0.20634016, 0.29952251, 0.33151193,\n",
       "        0.04763625, 0.07585177, 0.        , 0.30143853, 0.30280004,\n",
       "        0.09988097, 0.26266589, 0.22240602, 0.26861006, 0.44977586,\n",
       "        0.21363851, 0.13879173, 0.36698738, 0.47221246, 0.56775713],\n",
       "       [0.24012633, 0.20970435, 0.49374179, 0.56683902, 0.10443513,\n",
       "        0.29824876, 0.36892103, 0.30143853, 0.        , 0.11753272,\n",
       "        0.37925854, 0.14455071, 0.50907483, 0.13543747, 0.24432796,\n",
       "        0.12090159, 0.39932374, 0.20173577, 0.37922942, 0.39759179],\n",
       "       [0.27117382, 0.2581865 , 0.50830782, 0.58209684, 0.13421735,\n",
       "        0.28642698, 0.37286827, 0.30280004, 0.11753272, 0.        ,\n",
       "        0.38355598, 0.13397432, 0.52058526, 0.13690069, 0.29689127,\n",
       "        0.09728368, 0.40852458, 0.14554086, 0.41206376, 0.45294343],\n",
       "       [0.43900089, 0.37125165, 0.14041419, 0.2417443 , 0.39820329,\n",
       "        0.1377552 , 0.03510679, 0.09988097, 0.37925854, 0.38355598,\n",
       "        0.        , 0.33796144, 0.16822236, 0.35606811, 0.49736287,\n",
       "        0.29986895, 0.04480562, 0.45601656, 0.48261307, 0.58876142],\n",
       "       [0.2144752 , 0.29484824, 0.45470346, 0.49737097, 0.21710435,\n",
       "        0.25637015, 0.32896871, 0.26266589, 0.14455071, 0.13397432,\n",
       "        0.33796144, 0.        , 0.45432484, 0.07039078, 0.24069785,\n",
       "        0.09833813, 0.36493928, 0.15219345, 0.46938204, 0.4998711 ],\n",
       "       [0.56640603, 0.52620803, 0.06497089, 0.10362399, 0.54680744,\n",
       "        0.24634637, 0.16369669, 0.22240602, 0.50907483, 0.52058526,\n",
       "        0.16822236, 0.45432484, 0.        , 0.46080517, 0.61460741,\n",
       "        0.42775142, 0.17909956, 0.56227442, 0.63782014, 0.73802518],\n",
       "       [0.26960105, 0.32093978, 0.46182486, 0.50986155, 0.22340672,\n",
       "        0.25549521, 0.34067758, 0.26861006, 0.13543747, 0.13690069,\n",
       "        0.35606811, 0.07039078, 0.46080517, 0.        , 0.27784356,\n",
       "        0.09444775, 0.38706593, 0.12403713, 0.49527847, 0.52467963],\n",
       "       [0.092269  , 0.30692631, 0.61058438, 0.63620858, 0.28876458,\n",
       "        0.46198452, 0.49975907, 0.44977586, 0.24432796, 0.29689127,\n",
       "        0.49736287, 0.24069785, 0.61460741, 0.27784356, 0.        ,\n",
       "        0.30890158, 0.50722984, 0.3211749 , 0.4579131 , 0.41033354],\n",
       "       [0.27842439, 0.26089539, 0.41801845, 0.4892911 , 0.17165136,\n",
       "        0.19954164, 0.28621949, 0.21363851, 0.12090159, 0.09728368,\n",
       "        0.29986895, 0.09833813, 0.42775142, 0.09444775, 0.30890158,\n",
       "        0.        , 0.32837258, 0.17421104, 0.42633457, 0.48050509],\n",
       "       [0.44624218, 0.36830882, 0.1420688 , 0.24587061, 0.41165598,\n",
       "        0.17861133, 0.07663808, 0.13879173, 0.39932374, 0.40852458,\n",
       "        0.04480562, 0.36493928, 0.17909956, 0.38706593, 0.50722984,\n",
       "        0.32837258, 0.        , 0.48890089, 0.46791207, 0.57698651],\n",
       "       [0.32007625, 0.39026206, 0.56552701, 0.61224524, 0.26407052,\n",
       "        0.34362296, 0.44013943, 0.36698738, 0.20173577, 0.14554086,\n",
       "        0.45601656, 0.15219345, 0.56227442, 0.12403713, 0.3211749 ,\n",
       "        0.17421104, 0.48890089, 0.        , 0.55246951, 0.57402346],\n",
       "       [0.41712692, 0.17956463, 0.59065731, 0.70122269, 0.29467878,\n",
       "        0.48948616, 0.49311186, 0.47221246, 0.37922942, 0.41206376,\n",
       "        0.48261307, 0.46938204, 0.63782014, 0.49527847, 0.4579131 ,\n",
       "        0.42633457, 0.46791207, 0.55246951, 0.        , 0.1662031 ],\n",
       "       [0.39642875, 0.23332514, 0.69781391, 0.7905383 , 0.32828298,\n",
       "        0.58613718, 0.59787299, 0.56775713, 0.39759179, 0.45294343,\n",
       "        0.58876142, 0.4998711 , 0.73802518, 0.52467963, 0.41033354,\n",
       "        0.48050509, 0.57698651, 0.57402346, 0.1662031 , 0.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = mds_df.to_numpy()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fa79bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.3384913 , 0.70865547, 0.7452785 , 0.33900487,\n",
       "        0.52527337, 0.56363368, 0.50731892, 0.3037504 , 0.34302427,\n",
       "        0.55531893, 0.27130273, 0.71648145, 0.34103477, 0.11671668,\n",
       "        0.35219595, 0.56447888, 0.40488393, 0.52764922, 0.50146684],\n",
       "       [0.3384913 , 0.        , 0.62122187, 0.74059617, 0.18702798,\n",
       "        0.4484682 , 0.47625281, 0.42834473, 0.26526779, 0.32659582,\n",
       "        0.46961879, 0.37297148, 0.66563255, 0.40597626, 0.38824976,\n",
       "        0.33002245, 0.46589624, 0.49366622, 0.22714223, 0.29514717],\n",
       "       [0.70865547, 0.62122187, 0.        , 0.19702784, 0.65945799,\n",
       "        0.29659016, 0.17569109, 0.26101222, 0.62456403, 0.64298949,\n",
       "        0.17761845, 0.57518207, 0.08218563, 0.58419036, 0.77236533,\n",
       "        0.52877697, 0.17971147, 0.71536952, 0.74715836, 0.88270727],\n",
       "       [0.7452785 , 0.74059617, 0.19702784, 0.        , 0.77459939,\n",
       "        0.41276779, 0.31006682, 0.37888425, 0.71702917, 0.73632971,\n",
       "        0.30579708, 0.6291548 , 0.13108029, 0.6449549 , 0.80477895,\n",
       "        0.61893408, 0.3110167 , 0.77446626, 0.88701925, 1.        ],\n",
       "       [0.33900487, 0.18702798, 0.65945799, 0.77459939, 0.        ,\n",
       "        0.41599306, 0.496161  , 0.41934961, 0.13210634, 0.16977969,\n",
       "        0.50371157, 0.2746285 , 0.69169   , 0.28260075, 0.36527589,\n",
       "        0.21713225, 0.5207287 , 0.33403887, 0.37275712, 0.41526511],\n",
       "       [0.52527337, 0.4484682 , 0.29659016, 0.41276779, 0.41599306,\n",
       "        0.        , 0.14032013, 0.060258  , 0.37727301, 0.36231892,\n",
       "        0.17425493, 0.3242982 , 0.31161852, 0.32319144, 0.58439233,\n",
       "        0.25241236, 0.22593634, 0.43466959, 0.61918083, 0.74144059],\n",
       "       [0.56363368, 0.47625281, 0.17569109, 0.31006682, 0.496161  ,\n",
       "        0.14032013, 0.        , 0.09594952, 0.46667066, 0.47166376,\n",
       "        0.04440871, 0.41613254, 0.2070699 , 0.4309438 , 0.63217565,\n",
       "        0.36205644, 0.09694417, 0.55675915, 0.62376719, 0.75628593],\n",
       "       [0.50731892, 0.42834473, 0.26101222, 0.37888425, 0.41934961,\n",
       "        0.060258  , 0.09594952, 0.        , 0.38130794, 0.38303019,\n",
       "        0.12634552, 0.33226206, 0.28133491, 0.33978121, 0.56894885,\n",
       "        0.27024434, 0.1755661 , 0.46422467, 0.59733027, 0.71819054],\n",
       "       [0.3037504 , 0.26526779, 0.62456403, 0.71702917, 0.13210634,\n",
       "        0.37727301, 0.46667066, 0.38130794, 0.        , 0.14867429,\n",
       "        0.4797472 , 0.18285098, 0.64395972, 0.1713231 , 0.3090653 ,\n",
       "        0.15293578, 0.50512889, 0.25518785, 0.47971037, 0.50293805],\n",
       "       [0.34302427, 0.32659582, 0.64298949, 0.73632971, 0.16977969,\n",
       "        0.36231892, 0.47166376, 0.38303019, 0.14867429, 0.        ,\n",
       "        0.4851833 , 0.16947227, 0.65851996, 0.17317401, 0.37555584,\n",
       "        0.12306004, 0.5167676 , 0.18410349, 0.52124452, 0.5729557 ],\n",
       "       [0.55531893, 0.46961879, 0.17761845, 0.30579708, 0.50371157,\n",
       "        0.17425493, 0.04440871, 0.12634552, 0.4797472 , 0.4851833 ,\n",
       "        0.        , 0.42750799, 0.2127947 , 0.45041221, 0.62914456,\n",
       "        0.37932249, 0.05667736, 0.5768431 , 0.61048663, 0.74476014],\n",
       "       [0.27130273, 0.37297148, 0.57518207, 0.6291548 , 0.2746285 ,\n",
       "        0.3242982 , 0.41613254, 0.33226206, 0.18285098, 0.16947227,\n",
       "        0.42750799, 0.        , 0.57470313, 0.08904158, 0.30447335,\n",
       "        0.12439388, 0.4616339 , 0.19251876, 0.5937499 , 0.63231737],\n",
       "       [0.71648145, 0.66563255, 0.08218563, 0.13108029, 0.69169   ,\n",
       "        0.31161852, 0.2070699 , 0.28133491, 0.64395972, 0.65851996,\n",
       "        0.2127947 , 0.57470313, 0.        , 0.58290049, 0.77745431,\n",
       "        0.5410888 , 0.22655393, 0.71125513, 0.80681751, 0.93357295],\n",
       "       [0.34103477, 0.40597626, 0.58419036, 0.6449549 , 0.28260075,\n",
       "        0.32319144, 0.4309438 , 0.33978121, 0.1713231 , 0.17317401,\n",
       "        0.45041221, 0.08904158, 0.58290049, 0.        , 0.35146122,\n",
       "        0.1194727 , 0.48962325, 0.15690211, 0.62650787, 0.66369919],\n",
       "       [0.11671668, 0.38824976, 0.77236533, 0.80477895, 0.36527589,\n",
       "        0.58439233, 0.63217565, 0.56894885, 0.3090653 , 0.37555584,\n",
       "        0.62914456, 0.30447335, 0.77745431, 0.35146122, 0.        ,\n",
       "        0.39074841, 0.64162588, 0.40627367, 0.57924214, 0.51905586],\n",
       "       [0.35219595, 0.33002245, 0.52877697, 0.61893408, 0.21713225,\n",
       "        0.25241236, 0.36205644, 0.27024434, 0.15293578, 0.12306004,\n",
       "        0.37932249, 0.12439388, 0.5410888 , 0.1194727 , 0.39074841,\n",
       "        0.        , 0.41537846, 0.22037014, 0.53929654, 0.60782013],\n",
       "       [0.56447888, 0.46589624, 0.17971147, 0.3110167 , 0.5207287 ,\n",
       "        0.22593634, 0.09694417, 0.1755661 , 0.50512889, 0.5167676 ,\n",
       "        0.05667736, 0.4616339 , 0.22655393, 0.48962325, 0.64162588,\n",
       "        0.41537846, 0.        , 0.61844048, 0.59189044, 0.72986534],\n",
       "       [0.40488393, 0.49366622, 0.71536952, 0.77446626, 0.33403887,\n",
       "        0.43466959, 0.55675915, 0.46422467, 0.25518785, 0.18410349,\n",
       "        0.5768431 , 0.19251876, 0.71125513, 0.15690211, 0.40627367,\n",
       "        0.22037014, 0.61844048, 0.        , 0.69885229, 0.7261172 ],\n",
       "       [0.52764922, 0.22714223, 0.74715836, 0.88701925, 0.37275712,\n",
       "        0.61918083, 0.62376719, 0.59733027, 0.47971037, 0.52124452,\n",
       "        0.61048663, 0.5937499 , 0.80681751, 0.62650787, 0.57924214,\n",
       "        0.53929654, 0.59189044, 0.69885229, 0.        , 0.21024042],\n",
       "       [0.50146684, 0.29514717, 0.88270727, 1.        , 0.41526511,\n",
       "        0.74144059, 0.75628593, 0.71819054, 0.50293805, 0.5729557 ,\n",
       "        0.74476014, 0.63231737, 0.93357295, 0.66369919, 0.51905586,\n",
       "        0.60782013, 0.72986534, 0.7261172 , 0.21024042, 0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import MDS\n",
    "X_scaled = (a - np.min(a))/np.ptp(a)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc2865c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35048818,  0.02611491],\n",
       "       [ 0.15516774, -0.21450277],\n",
       "       [-0.42449671, -0.03862005],\n",
       "       [-0.51582821,  0.11788866],\n",
       "       [ 0.19800086, -0.0657779 ],\n",
       "       [-0.16861028,  0.09147086],\n",
       "       [-0.25725845, -0.00893795],\n",
       "       [-0.17754266,  0.03740001],\n",
       "       [ 0.18063172,  0.05073262],\n",
       "       [ 0.18568999,  0.14254422],\n",
       "       [-0.26096494, -0.04575556],\n",
       "       [ 0.11025107,  0.17382078],\n",
       "       [-0.44830262,  0.03354162],\n",
       "       [ 0.10367869,  0.21740909],\n",
       "       [ 0.409277  ,  0.00549899],\n",
       "       [ 0.06863795,  0.11446296],\n",
       "       [-0.27322953, -0.09757058],\n",
       "       [ 0.20098177,  0.31041052],\n",
       "       [ 0.18501907, -0.43318469],\n",
       "       [ 0.37840937, -0.41694574]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mds = MDS(2, random_state=0, dissimilarity='precomputed')\n",
    "X_mds = mds.fit_transform(X_scaled)\n",
    "X_mds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a74a59d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MDS plot using the Euclidean distances calculated above.\n",
    "x= X_mds[:,0]\n",
    "y= X_mds[:,1]\n",
    "\n",
    "for i in range(len(x)):\n",
    "    plt.scatter(x[i],y[i],c='blue')\n",
    "    plt.annotate(\n",
    "        company_list[i],\n",
    "        xy = (x[i], y[i]), xytext = (2, 2),\n",
    "        textcoords = 'offset points', ha = 'right', va = 'bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19723744",
   "metadata": {},
   "source": [
    "This MDS plot is not 100% accurate as we are compressing a 20 dimensional representation into a 2-d plot. But, we can see that the consultant companies are all clustered together. Target and Walmart (Retailers) are together. All the tech companies are almost close to each other along with some Finance companies like Bank of America and JPMC. Python doesn't know these categories but it is interesting that based on the topics distribution these companies have been automatically clustered together. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
